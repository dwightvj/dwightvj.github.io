---
layout: post
title: Blog Post 3
---

In this blog post I look at using the machine learning framework, Tensorflow, to gauge if an article is "fake news" based on an article's text and title. Our data hs been split into training and testing sets, but we wil begin with looking at the training data below. 


```python
# vectorization dependencies
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
import re
import string

# ML dependencies
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow import keras
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup

# visualization dependencies
import plotly.express as px 
import plotly.io as pio
```

    [nltk_data] Downloading package stopwords to
    [nltk_data]     C:\Users\avija\AppData\Roaming\nltk_data...
    [nltk_data]   Package stopwords is already up-to-date!
    
{::options parse_block_html="true" /}
<div class="gave-help">
I recommended that my peers give some explanation of the libraries and modules used so as to add more background to the task at hand. I also recommended that they give an explanation of some aspects of tensorlfow such as what keras, layers, and losses all do.
</div>
{::options parse_block_html="false" /}

Let's look at the above modules in detail:

- `tensorflow`: to implement machine learning techniques
- `keras`: acts as an interface for the TensorFlow library
- `layers` callable object that takes as input one or more tensors and that outputs one or more tensors.
- `losses` determine how far the predicted values deviate from the actual values in the training data.
- `re`: create regular expressions
- `string`: mainipulate stringsfor manipulating strings
- `plotly`: create interactive visualizations
- `numpy`: easily mainipulate arrays
- `pandas`: create dataframes

# Acquire Training Data

In order to determine if a news article is considered fake test we need to first have some training data. In our case the data below contains information concerning article text, title, as well as our predictor columns ('fake') where 0 indicates an article is true and 1 indicates an article is fake


```python
# provided courtesy of Dr. Phil Chodrow (the goat)
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"

# obtain data
df = pd.read_csv(train_url)
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and â€œClose Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



# Make a Dataset

Here I create a function called make_dataset, and do the following:

1. Remove stopwords from the article text and title (i.e. "the," "and," or "but")

2. Construct and return a tf.data.Dataset with two inputs and one output. The input should be of the form (title, text), and the output should consist only of the fake column. 

3. I call this function `make_dataset` on my training dataframe to produce a Dataset. I implement batching of size 100, so that I can tell my model to train on chunks of data rather than individual rows. This, in turn, increases the speed of training!

4. Split data into training and validation sets with 80% dedicated towards training data dn 20% towards validation.

Imported from the NLTK library stopwords consist of irrelevant words that do not add any value to our classifier. Examples of stop words include 'myself', 'you', 'your', 'about', 'with', etc.


```python
# stopwords
stop = stopwords.words("english")

def make_dataset(df):
    """
    create dataset that supports tensorflow operations
    
    df: raw data in question (provided above)
    return: data that has been cleaned of stopwords and is now considered a "tensorflow dataset"
    """
    # remove stopwords with for loop
    for i in ["text", "title"]:
        df[i] = df[i].str.lower().str.split()
        df[i] = df[i].apply(lambda x: [item for item in x if item not in stop]).apply(" ".join)

    # from_tensor_slices creates a dataset with a separate element for each row of the input tensor:
    tf_data = tf.data.Dataset.from_tensor_slices(
      (
        {"title" :  df[["title"]],"text" : df[["text"]]},
        {"fake" : df[["fake"]]}
      )
    )

    return tf_data
```


```python
data = make_dataset(df)
```

Once we have the data we care about we split this data into a training and validation set. Training data is used in creating our model and validation data is enables us to give an estimate of model skill while tuning model's hyperparameters. As such, the majority of our data (80%) is dedicated to training our model. 20% of our data is dedicated to our validation sample set. 


{::options parse_block_html="true" /}
<div class="got-help">
My peers reminded me to shuffle my data so that there is no bias in the number of true/false rows across the training and validation sets. As a result I ensure that I shuffle my data before performing an 80/20 split on my data.
```python
data = data.shuffle(buffer_size = len(data))
```
</div>
{::options parse_block_html="false" /}

```python
train_size = int(0.8*len(data))
val_size   = int(0.2*len(data))
train = data.take(train_size).batch(20)
val   = data.skip(train_size).take(val_size).batch(20)
```

# Model Dependencies


```python
def standardization(input_data):
    """
    make input data lowercase and remove any punctuation
    
    input_data: data in question
    return: cleaned data free from punctuation/upper case letters
    """
    lowercase = tf.strings.lower(input_data)
    no_punctuation = tf.strings.regex_replace(lowercase,
                                  '[%s]' % re.escape(string.punctuation),'')
    return no_punctuation
```

Create a layer for the purposes of vectorizes inputed data.`TextVectorization()` acheives this by providing a variety of arguments to sanitize our data. Since our `max_tokens` is 2000, this means we only consider the 2000 most popular words in our data. 

`output_sequence_length = 500` tells us that the output be padded to be exactly 500 values


```python
size_vocab = 2000
vectorize_layer = TextVectorization(
    standardize            = standardization,
    max_tokens             = size_vocab,
    output_mode            = "int",
    output_sequence_length = 500)
```

Use `adapt` to apply the vectorize layer from above on the respective features (i.e. `text` and `title`) in our training data


```python
vectorize_layer.adapt(train.map(lambda x, y: x["text"]))
vectorize_layer.adapt(train.map(lambda x, y: x["title"]))
```

Let us create Tensorflow-understandable input. Using `keras.Input()` we can create text_input and title_input indicating shape, name, as well as the datatype of our "features"


```python
text_input = keras.Input(
    shape = (1,),
    name = "text",
    dtype = "string"
)
```


```python
title_input = keras.Input(
    shape = (1,),
    name = "title",
    dtype = "string"
)
```


```python
# shared layer used acros all models created below. 
shared_layer = layers.Embedding(size_vocab, 10, name = "embedding")
```


# Model 1 - Working With the Title Feature

Add more layers:
- `Embedding` gauge words that associate with fake news (10 dimensions in our case)
- `Dropout` prevent overfitting
- `GlobalAveragePooling1D` compute average over inout data we care about moving our data from 10 dimensions to 1Dto take
- `Dense` Final layer which gives us our output (it is the same size as the number of predicted classes we want to predict (false or true)


```python
title_features = vectorize_layer(title_input)
title_features = shared_layer(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.Dense(32, activation='relu')(title_features)
title_output = layers.Dense(2, name = "fake")(title_features)
```

Here, we use `keras.Model()` to construct our model`


```python
# construct our model
title_model = keras.Model(
    inputs = title_input,
    outputs = title_output
)

# summarize key model features such as the model parameters, number of layers, and shapes of those layers
# note that the last Dense layer has a output shape of (, 2) indicating 2 classes are being predicted (fake/true)
title_model.summary()
```

    Model: "model"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    title (InputLayer)           [(None, 1)]               0         
    _________________________________________________________________
    text_vectorization (TextVect (None, 500)               0         
    _________________________________________________________________
    embedding (Embedding)        (None, 500, 10)           20000     
    _________________________________________________________________
    dropout (Dropout)            (None, 500, 10)           0         
    _________________________________________________________________
    global_average_pooling1d (Gl (None, 10)                0         
    _________________________________________________________________
    dropout_1 (Dropout)          (None, 10)                0         
    _________________________________________________________________
    dense (Dense)                (None, 32)                352       
    _________________________________________________________________
    fake (Dense)                 (None, 2)                 66        
    =================================================================
    Total params: 20,418
    Trainable params: 20,418
    Non-trainable params: 0
    _________________________________________________________________
    

Here we aim to visualize our model's architecture layer by layer

At this point, we compile and fit our model. We use the "adam" optimizer - a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. Additionally, our loss function is SparseCategoricalCrossentropy() which especially finetuned for models with two or more label classes. 


```python
title_model.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
history = title_model.fit(train, 
                    validation_data=val,
                    epochs = 50)
```

    Epoch 1/50
    898/898 [==============================] - 4s 3ms/step - loss: 0.6899 - accuracy: 0.5296 - val_loss: 0.5745 - val_accuracy: 0.8042
    Epoch 2/50
    898/898 [==============================] - 2s 3ms/step - loss: 0.4753 - accuracy: 0.8155 - val_loss: 0.2663 - val_accuracy: 0.8986
    Epoch 3/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.2556 - accuracy: 0.9014 - val_loss: 0.2070 - val_accuracy: 0.9142
    Epoch 4/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.2026 - accuracy: 0.9201 - val_loss: 0.2031 - val_accuracy: 0.9084
    Epoch 5/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1807 - accuracy: 0.9248 - val_loss: 0.1417 - val_accuracy: 0.9441
    Epoch 6/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1647 - accuracy: 0.9376 - val_loss: 0.1407 - val_accuracy: 0.9445
    Epoch 7/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1556 - accuracy: 0.9371 - val_loss: 0.1326 - val_accuracy: 0.9503
    Epoch 8/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1459 - accuracy: 0.9415 - val_loss: 0.1374 - val_accuracy: 0.9423
    Epoch 9/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1364 - accuracy: 0.9467 - val_loss: 0.1238 - val_accuracy: 0.9510
    Epoch 10/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1296 - accuracy: 0.9515 - val_loss: 0.1312 - val_accuracy: 0.9459
    Epoch 11/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1208 - accuracy: 0.9518 - val_loss: 0.1109 - val_accuracy: 0.9583
    Epoch 12/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1276 - accuracy: 0.9509 - val_loss: 0.1179 - val_accuracy: 0.9537
    Epoch 13/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1221 - accuracy: 0.9507 - val_loss: 0.1620 - val_accuracy: 0.9285
    Epoch 14/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1248 - accuracy: 0.9523 - val_loss: 0.1001 - val_accuracy: 0.9639
    Epoch 15/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1189 - accuracy: 0.9531 - val_loss: 0.1048 - val_accuracy: 0.9579
    Epoch 16/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1235 - accuracy: 0.9500 - val_loss: 0.1088 - val_accuracy: 0.9566
    Epoch 17/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1087 - accuracy: 0.9585 - val_loss: 0.1291 - val_accuracy: 0.9468
    Epoch 18/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1135 - accuracy: 0.9557 - val_loss: 0.1236 - val_accuracy: 0.9463
    Epoch 19/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1097 - accuracy: 0.9577 - val_loss: 0.0988 - val_accuracy: 0.9586
    Epoch 20/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1133 - accuracy: 0.9563 - val_loss: 0.0845 - val_accuracy: 0.9697
    Epoch 21/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1147 - accuracy: 0.9553 - val_loss: 0.0863 - val_accuracy: 0.9666
    Epoch 22/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1084 - accuracy: 0.9568 - val_loss: 0.0849 - val_accuracy: 0.9650
    Epoch 23/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1010 - accuracy: 0.9618 - val_loss: 0.1488 - val_accuracy: 0.9396
    Epoch 24/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1048 - accuracy: 0.9609 - val_loss: 0.1179 - val_accuracy: 0.9497
    Epoch 25/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1058 - accuracy: 0.9583 - val_loss: 0.0897 - val_accuracy: 0.9652
    Epoch 26/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.0996 - accuracy: 0.9604 - val_loss: 0.1324 - val_accuracy: 0.9436
    Epoch 27/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1088 - accuracy: 0.9574 - val_loss: 0.0875 - val_accuracy: 0.9664
    Epoch 28/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1000 - accuracy: 0.9627 - val_loss: 0.0868 - val_accuracy: 0.9675
    Epoch 29/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1000 - accuracy: 0.9611 - val_loss: 0.0985 - val_accuracy: 0.9610
    Epoch 30/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1040 - accuracy: 0.9590 - val_loss: 0.0983 - val_accuracy: 0.9630
    Epoch 31/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1029 - accuracy: 0.9623 - val_loss: 0.0768 - val_accuracy: 0.9735
    Epoch 32/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1077 - accuracy: 0.9590 - val_loss: 0.1096 - val_accuracy: 0.9546
    Epoch 33/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1055 - accuracy: 0.9592 - val_loss: 0.0989 - val_accuracy: 0.9601
    Epoch 34/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.0987 - accuracy: 0.9613 - val_loss: 0.0929 - val_accuracy: 0.9650
    Epoch 35/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1025 - accuracy: 0.9610 - val_loss: 0.0852 - val_accuracy: 0.9659
    Epoch 36/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.0958 - accuracy: 0.9640 - val_loss: 0.0908 - val_accuracy: 0.9628
    Epoch 37/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.0909 - accuracy: 0.9637 - val_loss: 0.0883 - val_accuracy: 0.9630
    Epoch 38/50
    898/898 [==============================] - 4s 5ms/step - loss: 0.0989 - accuracy: 0.9596 - val_loss: 0.0750 - val_accuracy: 0.9742
    Epoch 39/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.0999 - accuracy: 0.9625 - val_loss: 0.0994 - val_accuracy: 0.9606
    Epoch 40/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.0968 - accuracy: 0.9609 - val_loss: 0.0847 - val_accuracy: 0.9666
    Epoch 41/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1037 - accuracy: 0.9591 - val_loss: 0.0904 - val_accuracy: 0.9650
    Epoch 42/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.1001 - accuracy: 0.9621 - val_loss: 0.0747 - val_accuracy: 0.9724
    Epoch 43/50
    898/898 [==============================] - 4s 5ms/step - loss: 0.1046 - accuracy: 0.9558 - val_loss: 0.0978 - val_accuracy: 0.9606
    Epoch 44/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.0890 - accuracy: 0.9643 - val_loss: 0.0927 - val_accuracy: 0.9621
    Epoch 45/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.1033 - accuracy: 0.9601 - val_loss: 0.1085 - val_accuracy: 0.9550
    Epoch 46/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.0959 - accuracy: 0.9634 - val_loss: 0.0884 - val_accuracy: 0.9673
    Epoch 47/50
    898/898 [==============================] - 4s 4ms/step - loss: 0.0927 - accuracy: 0.9641 - val_loss: 0.0956 - val_accuracy: 0.9590
    Epoch 48/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.0935 - accuracy: 0.9633 - val_loss: 0.0862 - val_accuracy: 0.9641
    Epoch 49/50
    898/898 [==============================] - 3s 4ms/step - loss: 0.1008 - accuracy: 0.9583 - val_loss: 0.0946 - val_accuracy: 0.9621
    Epoch 50/50
    898/898 [==============================] - 3s 3ms/step - loss: 0.0963 - accuracy: 0.9603 - val_loss: 0.0890 - val_accuracy: 0.9644
    

On our last epoch we obtained validation accuracy of nearly 97%!


```python
from matplotlib import pyplot as plt
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
```

    

![png](/images/output_33_1.png)
    


Here we use matplotlib to visualize the accuracy of our training and validation sets. Fortunately there are no large deviations at the end of our 50 epochs, and our training results are not susbtantially better than our validation results, which may indicate overfitting is not occuring.

# Model 2 - Working With the Text Feature

### Now we follow the same methodology from Model 1 with a focus on the Text Feature from our data


```python
text_features = vectorize_layer(text_input)
text_features = shared_layer(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.Dense(32, activation='relu')(text_features)
text_output = layers.Dense(2, name = "fake")(text_features)
```


```python
text_model = keras.Model(
    inputs = text_input,
    outputs = text_output
)

text_model.summary()
```

    Model: "model_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    text (InputLayer)            [(None, 1)]               0         
    _________________________________________________________________
    text_vectorization (TextVect (None, 500)               0         
    _________________________________________________________________
    embedding (Embedding)        (None, 500, 10)           20000     
    _________________________________________________________________
    dropout_2 (Dropout)          (None, 500, 10)           0         
    _________________________________________________________________
    global_average_pooling1d_1 ( (None, 10)                0         
    _________________________________________________________________
    dropout_3 (Dropout)          (None, 10)                0         
    _________________________________________________________________
    dense_1 (Dense)              (None, 32)                352       
    _________________________________________________________________
    fake (Dense)                 (None, 2)                 66        
    =================================================================
    Total params: 20,418
    Trainable params: 20,418
    Non-trainable params: 0
    _________________________________________________________________
    


```python
text_model.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```


```python
history = text_model.fit(train, 
                    validation_data=val,
                    epochs = 50)
```

    Epoch 1/50
    898/898 [==============================] - 7s 7ms/step - loss: 0.4824 - accuracy: 0.7730 - val_loss: 0.2121 - val_accuracy: 0.9301
    Epoch 2/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.1999 - accuracy: 0.9310 - val_loss: 0.1525 - val_accuracy: 0.9492
    Epoch 3/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.1686 - accuracy: 0.9454 - val_loss: 0.1393 - val_accuracy: 0.9552
    Epoch 4/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.1440 - accuracy: 0.9518 - val_loss: 0.1328 - val_accuracy: 0.9528
    Epoch 5/50
    898/898 [==============================] - 7s 7ms/step - loss: 0.1284 - accuracy: 0.9607 - val_loss: 0.1114 - val_accuracy: 0.9650
    Epoch 6/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.1088 - accuracy: 0.9633 - val_loss: 0.0925 - val_accuracy: 0.9719
    Epoch 7/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.1126 - accuracy: 0.9657 - val_loss: 0.0984 - val_accuracy: 0.9673
    Epoch 8/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.1023 - accuracy: 0.9693 - val_loss: 0.0845 - val_accuracy: 0.9726
    Epoch 9/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.0917 - accuracy: 0.9715 - val_loss: 0.0862 - val_accuracy: 0.9748
    Epoch 10/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0899 - accuracy: 0.9713 - val_loss: 0.0812 - val_accuracy: 0.9742
    Epoch 11/50
    898/898 [==============================] - 8s 8ms/step - loss: 0.0855 - accuracy: 0.9746 - val_loss: 0.0709 - val_accuracy: 0.9771
    Epoch 12/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0835 - accuracy: 0.9739 - val_loss: 0.0674 - val_accuracy: 0.9791
    Epoch 13/50
    898/898 [==============================] - 6s 7ms/step - loss: 0.0721 - accuracy: 0.9777 - val_loss: 0.0691 - val_accuracy: 0.9797
    Epoch 14/50
    898/898 [==============================] - 6s 7ms/step - loss: 0.0767 - accuracy: 0.9757 - val_loss: 0.0664 - val_accuracy: 0.9811
    Epoch 15/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0704 - accuracy: 0.9777 - val_loss: 0.0600 - val_accuracy: 0.9808
    Epoch 16/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 0.0497 - val_accuracy: 0.9853
    Epoch 17/50
    898/898 [==============================] - 6s 7ms/step - loss: 0.0670 - accuracy: 0.9789 - val_loss: 0.0499 - val_accuracy: 0.9846
    Epoch 18/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 0.0493 - val_accuracy: 0.9824
    Epoch 19/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0572 - accuracy: 0.9808 - val_loss: 0.0397 - val_accuracy: 0.9884
    Epoch 20/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.0451 - val_accuracy: 0.9862
    Epoch 21/50
    898/898 [==============================] - 7s 7ms/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0428 - val_accuracy: 0.9875
    Epoch 22/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 0.0362 - val_accuracy: 0.9877
    Epoch 23/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.0348 - val_accuracy: 0.9900
    Epoch 24/50
    898/898 [==============================] - 7s 7ms/step - loss: 0.0426 - accuracy: 0.9849 - val_loss: 0.0425 - val_accuracy: 0.9862
    Epoch 25/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 0.0370 - val_accuracy: 0.9866
    Epoch 26/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 0.0319 - val_accuracy: 0.9900
    Epoch 27/50
    898/898 [==============================] - 8s 8ms/step - loss: 0.0410 - accuracy: 0.9855 - val_loss: 0.0321 - val_accuracy: 0.9882
    Epoch 28/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 0.0263 - val_accuracy: 0.9926
    Epoch 29/50
    898/898 [==============================] - 6s 7ms/step - loss: 0.0424 - accuracy: 0.9858 - val_loss: 0.0253 - val_accuracy: 0.9918
    Epoch 30/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0414 - accuracy: 0.9858 - val_loss: 0.0280 - val_accuracy: 0.9909
    Epoch 31/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.0300 - val_accuracy: 0.9898
    Epoch 32/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.0324 - val_accuracy: 0.9891
    Epoch 33/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.0163 - val_accuracy: 0.9942
    Epoch 34/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0239 - val_accuracy: 0.9904
    Epoch 35/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0359 - accuracy: 0.9892 - val_loss: 0.0250 - val_accuracy: 0.9920
    Epoch 36/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0374 - accuracy: 0.9865 - val_loss: 0.0183 - val_accuracy: 0.9933
    Epoch 37/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0307 - accuracy: 0.9886 - val_loss: 0.0250 - val_accuracy: 0.9911
    Epoch 38/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0274 - accuracy: 0.9902 - val_loss: 0.0189 - val_accuracy: 0.9931
    Epoch 39/50
    898/898 [==============================] - 6s 7ms/step - loss: 0.0262 - accuracy: 0.9899 - val_loss: 0.0138 - val_accuracy: 0.9951
    Epoch 40/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0291 - accuracy: 0.9894 - val_loss: 0.0219 - val_accuracy: 0.9915
    Epoch 41/50
    898/898 [==============================] - 6s 7ms/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.0147 - val_accuracy: 0.9942
    Epoch 42/50
    898/898 [==============================] - 5s 6ms/step - loss: 0.0222 - accuracy: 0.9910 - val_loss: 0.0183 - val_accuracy: 0.9947
    Epoch 43/50
    898/898 [==============================] - 5s 6ms/step - loss: 0.0208 - accuracy: 0.9917 - val_loss: 0.0152 - val_accuracy: 0.9949
    Epoch 44/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.0186 - val_accuracy: 0.9940
    Epoch 45/50
    898/898 [==============================] - 8s 8ms/step - loss: 0.0241 - accuracy: 0.9907 - val_loss: 0.0184 - val_accuracy: 0.9931
    Epoch 46/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0250 - accuracy: 0.9902 - val_loss: 0.0252 - val_accuracy: 0.9906
    Epoch 47/50
    898/898 [==============================] - 5s 6ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0162 - val_accuracy: 0.9953
    Epoch 48/50
    898/898 [==============================] - 6s 6ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0184 - val_accuracy: 0.9935
    Epoch 49/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0238 - accuracy: 0.9912 - val_loss: 0.0156 - val_accuracy: 0.9947
    Epoch 50/50
    898/898 [==============================] - 6s 7ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0138 - val_accuracy: 0.9940
    

On our last epoch we obtained validation accuracy of 99%!


```python
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
```


![png](/images/output_42_1.png)
    


Here we use matplotlib to visualize the accuracy of our training and validation sets. Fortunately there are no large deviations at the end of our 50 epochs, and our training results are not susbtantially better than our validation results, which may indicate overfitting is not occuring.

# Model 3 - Putting it Altogether

In our final model we look at both the title and text features when predicting if an article is considered to be fake news. Seeing as we've done all the heavy lifting above, this model is realtively straight forward.


```python
# concatenate the input features from both title and text
main = layers.concatenate([title_features, text_features], axis = 1)
```


```python
# dditional Dense layers to prevent overfitting
main = layers.Dense(32, activation='relu')(main)
# predicting 2 classes (as before)
output = layers.Dense(2, name = "fake")(main)
```


```python
final_model = keras.Model(
    inputs = [title_input, text_input],
    outputs = output
)

final_model.summary()
```

    Model: "model_2"
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    title (InputLayer)              [(None, 1)]          0                                            
    __________________________________________________________________________________________________
    text (InputLayer)               [(None, 1)]          0                                            
    __________________________________________________________________________________________________
    text_vectorization (TextVectori (None, 500)          0           title[0][0]                      
                                                                     text[0][0]                       
    __________________________________________________________________________________________________
    embedding (Embedding)           (None, 500, 10)      20000       text_vectorization[0][0]         
                                                                     text_vectorization[1][0]         
    __________________________________________________________________________________________________
    dropout (Dropout)               (None, 500, 10)      0           embedding[0][0]                  
    __________________________________________________________________________________________________
    dropout_2 (Dropout)             (None, 500, 10)      0           embedding[1][0]                  
    __________________________________________________________________________________________________
    global_average_pooling1d (Globa (None, 10)           0           dropout[0][0]                    
    __________________________________________________________________________________________________
    global_average_pooling1d_1 (Glo (None, 10)           0           dropout_2[0][0]                  
    __________________________________________________________________________________________________
    dropout_1 (Dropout)             (None, 10)           0           global_average_pooling1d[0][0]   
    __________________________________________________________________________________________________
    dropout_3 (Dropout)             (None, 10)           0           global_average_pooling1d_1[0][0] 
    __________________________________________________________________________________________________
    dense (Dense)                   (None, 32)           352         dropout_1[0][0]                  
    __________________________________________________________________________________________________
    dense_1 (Dense)                 (None, 32)           352         dropout_3[0][0]                  
    __________________________________________________________________________________________________
    concatenate (Concatenate)       (None, 64)           0           dense[0][0]                      
                                                                     dense_1[0][0]                    
    __________________________________________________________________________________________________
    dense_2 (Dense)                 (None, 32)           2080        concatenate[0][0]                
    __________________________________________________________________________________________________
    fake (Dense)                    (None, 2)            66          dense_2[0][0]                    
    ==================================================================================================
    Total params: 22,850
    Trainable params: 22,850
    Non-trainable params: 0
    __________________________________________________________________________________________________
    


```python
final_model.compile(optimizer = "adam",
              loss = losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']
)
```

{::options parse_block_html="true" /}
<div class="gave-help">
I recommended that my peers include a png of their final model architecture to add to their overall blog post for the sake of clarity and completeness.
</div>
{::options parse_block_html="false" /}

```python
keras.utils.plot_model(final_model)
```
  
    
![png](/images/output_model_architecture.png)


```python
history = final_model.fit(train, 
                    validation_data=val,
                    epochs = 50)
```

    Epoch 1/50
    898/898 [==============================] - 10s 10ms/step - loss: 0.1208 - accuracy: 0.9651 - val_loss: 0.0144 - val_accuracy: 0.9960
    Epoch 2/50
    898/898 [==============================] - 7s 8ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0099 - val_accuracy: 0.9969
    Epoch 3/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0077 - val_accuracy: 0.9964
    Epoch 4/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.0054 - val_accuracy: 0.9975
    Epoch 5/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.0045 - val_accuracy: 0.9989
    Epoch 6/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0057 - val_accuracy: 0.9978
    Epoch 7/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.0051 - val_accuracy: 0.9971
    Epoch 8/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.0039 - val_accuracy: 0.9987
    Epoch 9/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0051 - val_accuracy: 0.9982
    Epoch 10/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 0.0035 - val_accuracy: 0.9996
    Epoch 11/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.0046 - val_accuracy: 0.9989
    Epoch 12/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0023 - val_accuracy: 0.9993
    Epoch 13/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.0037 - val_accuracy: 0.9989
    Epoch 14/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0044 - val_accuracy: 0.9984
    Epoch 15/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0033 - val_accuracy: 0.9989
    Epoch 16/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.0013 - val_accuracy: 1.0000
    Epoch 17/50
    898/898 [==============================] - 9s 11ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0021 - val_accuracy: 0.9996
    Epoch 18/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.0030 - val_accuracy: 0.9996
    Epoch 19/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.0015 - val_accuracy: 0.9998
    Epoch 20/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.0014 - val_accuracy: 0.9998
    Epoch 21/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 0.9991
    Epoch 22/50
    898/898 [==============================] - 12s 13ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0016 - val_accuracy: 1.0000
    Epoch 23/50
    898/898 [==============================] - 8s 8ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0017 - val_accuracy: 0.9996
    Epoch 24/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0012 - val_accuracy: 0.9998
    Epoch 25/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 9.8486e-04 - val_accuracy: 1.0000
    Epoch 26/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 9.4865e-04 - val_accuracy: 0.9998
    Epoch 27/50
    898/898 [==============================] - 8s 8ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0040 - val_accuracy: 0.9991
    Epoch 28/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 4.9361e-04 - val_accuracy: 1.0000
    Epoch 29/50
    898/898 [==============================] - 9s 10ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0029 - val_accuracy: 0.9993
    Epoch 30/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0043 - val_accuracy: 0.9982
    Epoch 31/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.0033 - val_accuracy: 0.9989
    Epoch 32/50
    898/898 [==============================] - 8s 9ms/step - loss: 0.0065 - accuracy: 0.9970 - val_loss: 8.3160e-04 - val_accuracy: 1.0000
    Epoch 33/50
    898/898 [==============================] - 13s 15ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0322 - val_accuracy: 0.9875
    Epoch 34/50
    898/898 [==============================] - 13s 15ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 6.7847e-04 - val_accuracy: 1.0000
    Epoch 35/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 7.9737e-04 - val_accuracy: 1.0000
    Epoch 36/50
    898/898 [==============================] - 12s 13ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 7.2818e-04 - val_accuracy: 1.0000
    Epoch 37/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 4.7164e-04 - val_accuracy: 1.0000
    Epoch 38/50
    898/898 [==============================] - 12s 14ms/step - loss: 0.0063 - accuracy: 0.9973 - val_loss: 3.1085e-04 - val_accuracy: 1.0000
    Epoch 39/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 9.4528e-04 - val_accuracy: 1.0000
    Epoch 40/50
    898/898 [==============================] - 12s 13ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 1.3408e-04 - val_accuracy: 1.0000
    Epoch 41/50
    898/898 [==============================] - 13s 14ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 6.0034e-04 - val_accuracy: 1.0000
    Epoch 42/50
    898/898 [==============================] - 12s 13ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0069 - val_accuracy: 0.9969
    Epoch 43/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 4.5590e-04 - val_accuracy: 1.0000
    Epoch 44/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 5.6639e-04 - val_accuracy: 0.9998
    Epoch 45/50
    898/898 [==============================] - 12s 13ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0011 - val_accuracy: 0.9998
    Epoch 46/50
    898/898 [==============================] - 10s 11ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 0.9991
    Epoch 47/50
    898/898 [==============================] - 11s 13ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 3.4098e-04 - val_accuracy: 1.0000
    Epoch 48/50
    898/898 [==============================] - 12s 13ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 4.9378e-04 - val_accuracy: 1.0000
    Epoch 49/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 4.0484e-04 - val_accuracy: 1.0000
    Epoch 50/50
    898/898 [==============================] - 11s 12ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 8.3986e-04 - val_accuracy: 1.0000
    

On our last epoch we obtained nearly perfect validation accuracy! Model 3 performed the best!


```python
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])
```

    
![png](/images/output_53_1.png)
    


Here we use matplotlib to visualize the accuracy of our training and validation sets. Fortunately there are no large deviations at the end of our 50 epochs, and our training results are not susbtantially better than our validation results, which may indicate overfitting is not occuring.

# Model Evaluation

Now we proceed to test our "final_model" on some novel data



```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
test_df = pd.read_csv(test_url)
test_data = make_dataset(test_df)
```


```python
final_model.evaluate(test_data)
```

    22449/22449 [==============================] - 39s 2ms/step - loss: 0.1216 - accuracy: 0.9820
    




    [0.12163076549768448, 0.9820482134819031]



The value of our loss function is 0.122 with an accuracy of 98.2%!


{::options parse_block_html="true" /}
<div class="got-help">
My peers recommended I give some explanation as to how exactly the visualization below is formed. As a result I talk more about how weights are extracted and what their meaning is in the context of this problem.
</div>
{::options parse_block_html="false" /}

# Embedding Visualizations - 2D

Based on our embedding layer we are able to create a bridge across words and labels (i.e. truth and false). As a result we can now look to see which words frequently appear in either the true or false category

First we extract weights from our emebedding layer


```python
weights = final_model.get_layer('embedding').get_weights()[0] 
# vectorize our vocab
vocab = vectorize_layer.get_vocabulary()
```


```python
from sklearn.decomposition import PCA
# transform weights into 2D vector for plotting
# we acheieve this using sklearn decomposition through PCA!
pca = PCA(n_components=2)
weights = pca.fit_transform(weights)

embedding_df = pd.DataFrame({
    'word' : vocab, 
    'x0'   : weights[:,0],
    'x1'   : weights[:,1]
})
embedding_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word</th>
      <th>x0</th>
      <th>x1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td></td>
      <td>0.661790</td>
      <td>-0.591927</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[UNK]</td>
      <td>0.471012</td>
      <td>-0.805895</td>
    </tr>
    <tr>
      <th>2</th>
      <td>trump</td>
      <td>-0.495591</td>
      <td>-1.512234</td>
    </tr>
    <tr>
      <th>3</th>
      <td>video</td>
      <td>-13.268363</td>
      <td>0.687738</td>
    </tr>
    <tr>
      <th>4</th>
      <td>us</td>
      <td>3.649328</td>
      <td>-2.246659</td>
    </tr>
  </tbody>
</table>
</div>



Now, we create a 2D Scatterplot


```python
import plotly.express as px 
fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1", 
                 size = list(np.ones(len(embedding_df))),
                 size_max = 2,
                 hover_name = "word",
                 title = '2D Scatterplot Of Embedding Layer Weights')

fig.show()
```

{% include blogpost3.html %}